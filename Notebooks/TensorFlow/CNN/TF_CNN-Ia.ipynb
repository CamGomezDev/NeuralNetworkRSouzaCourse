{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color:rgb(0,120,170)\">Neural Networks and Deep Learning</h1>\n",
    "<h2 style=\"color:rgb(0,120,170)\"> Predictive Analysis - Image Processing</h2>\n",
    "\n",
    "[source](https://www.analyticsvidhya.com/blog/2020/02/learn-image-classification-cnn-convolutional-neural-networks-3-datasets/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classify handwritten digits using the famous MNIST data\n",
    "\n",
    "![](https://cdn.analyticsvidhya.com/wp-content/uploads/2020/02/mnist.png)\n",
    "\n",
    "The goal in this task is to take an image of a handwritten single digit, and determine what that digit is.  \n",
    "\n",
    "The data for this competition were taken from the MNIST dataset. The MNIST (\"Modified National Institute of Standards and Technology\") dataset is a classic within the Machine Learning community that has been extensively studied.  More detail about the dataset, including Machine Learning algorithms that have been tried on it and their levels of success, can be found at http://yann.lecun.com/exdb/mnist/index.html.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import glob\n",
    "import math\n",
    "import random\n",
    "import pickle\n",
    "import pylab\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.font_manager import FontProperties\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn import model_selection\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "#matplotlib.rcdefaults()\n",
    "#matplotlib.verbose.set_level('silent')\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import np_utils\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "# loading the dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "# let's print the shape of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape (60000, 28, 28)\n",
      "y_train shape (60000,)\n",
      "X_test shape (10000, 28, 28)\n",
      "y_test shape (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"y_train shape\", y_train.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"y_test shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening the images from the 28x28 pixels to 1D 787 pixels\n",
    "X_train = X_train.reshape(60000, 784)\n",
    "X_test = X_test.reshape(10000, 784)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (60000,)\n",
      "Shape after one-hot encoding:  (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding using keras' numpy-related utilities\n",
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 79,510\n",
      "Trainable params: 79,510\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.3813 - accuracy: 0.8941 - val_loss: 0.1997 - val_accuracy: 0.9420\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.1772 - accuracy: 0.9501 - val_loss: 0.1554 - val_accuracy: 0.9555\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1324 - accuracy: 0.9618 - val_loss: 0.1236 - val_accuracy: 0.9621\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.1036 - accuracy: 0.9703 - val_loss: 0.1050 - val_accuracy: 0.9685\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0868 - accuracy: 0.9748 - val_loss: 0.0932 - val_accuracy: 0.9723\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0724 - accuracy: 0.9792 - val_loss: 0.0924 - val_accuracy: 0.9730\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0621 - accuracy: 0.9822 - val_loss: 0.0856 - val_accuracy: 0.9732\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 1s 3ms/step - loss: 0.0538 - accuracy: 0.9845 - val_loss: 0.0777 - val_accuracy: 0.9761\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0467 - accuracy: 0.9870 - val_loss: 0.0769 - val_accuracy: 0.9766\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 1s 2ms/step - loss: 0.0399 - accuracy: 0.9889 - val_loss: 0.0785 - val_accuracy: 0.9751\n",
      "CPU times: user 16.9 s, sys: 1.25 s, total: 18.1 s\n",
      "Wall time: 12.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc16f9795c0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_shape=(784,), activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# looking at the model summary\n",
    "model.summary()\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "# training the model for 10 epochs\n",
    "%time model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 1ms/step - loss: 0.0785 - accuracy: 0.9751\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07849335670471191, 0.9750999808311462]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the input vector from the 28x28 pixels\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the data to help with the training\n",
    "X_train /= 255\n",
    "X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape before one-hot encoding:  (60000,)\n",
      "Shape after one-hot encoding:  (60000, 10)\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding using keras' numpy-related utilities\n",
    "n_classes = 10\n",
    "print(\"Shape before one-hot encoding: \", y_train.shape)\n",
    "Y_train = np_utils.to_categorical(y_train, n_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, n_classes)\n",
    "print(\"Shape after one-hot encoding: \", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 10)        100       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 26, 26, 10)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6760)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               676100    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 677,210\n",
      "Trainable params: 677,210\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "469/469 [==============================] - 12s 27ms/step - loss: 0.2410 - accuracy: 0.9307 - val_loss: 0.1209 - val_accuracy: 0.9643\n",
      "Epoch 2/10\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0830 - accuracy: 0.9756 - val_loss: 0.0691 - val_accuracy: 0.9786\n",
      "Epoch 3/10\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.0520 - accuracy: 0.9843 - val_loss: 0.0593 - val_accuracy: 0.9810\n",
      "Epoch 4/10\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.0359 - accuracy: 0.9893 - val_loss: 0.0568 - val_accuracy: 0.9814\n",
      "Epoch 5/10\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.0242 - accuracy: 0.9927 - val_loss: 0.0527 - val_accuracy: 0.9830\n",
      "Epoch 6/10\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.0178 - accuracy: 0.9948 - val_loss: 0.0541 - val_accuracy: 0.9819\n",
      "Epoch 7/10\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.0126 - accuracy: 0.9964 - val_loss: 0.0551 - val_accuracy: 0.9818\n",
      "Epoch 8/10\n",
      "469/469 [==============================] - 12s 26ms/step - loss: 0.0086 - accuracy: 0.9977 - val_loss: 0.0593 - val_accuracy: 0.9822\n",
      "Epoch 9/10\n",
      "469/469 [==============================] - 11s 24ms/step - loss: 0.0071 - accuracy: 0.9983 - val_loss: 0.0580 - val_accuracy: 0.9827\n",
      "Epoch 10/10\n",
      "469/469 [==============================] - 12s 25ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0626 - val_accuracy: 0.9828\n",
      "CPU times: user 3min 53s, sys: 4.38 s, total: 3min 58s\n",
      "Wall time: 2min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fc17282b780>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# building a linear stack of layers with the sequential model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(10, kernel_size=(3,3), strides=(1,1), padding='valid', activation='relu', input_shape=(28,28,1)))\n",
    "model.add(MaxPool2D(pool_size=(1,1)))\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "# looking at the model summary\n",
    "model.summary()\n",
    "\n",
    "# compiling the sequential model\n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')\n",
    "\n",
    "\n",
    "# training the model for 10 epochs\n",
    "%time model.fit(X_train, Y_train, batch_size=128, epochs=10, validation_data=(X_test, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0626 - accuracy: 0.9828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06261526048183441, 0.9828000068664551]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
