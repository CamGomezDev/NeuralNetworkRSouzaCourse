{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, MaxPooling2D, Flatten, BatchNormalization, Reshape, LeakyReLU, multiply, Embedding, UpSampling2D, Dropout\n",
    "from tensorflow.keras.models import Model, load_model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def req_model(no_of_labels):\n",
    "    input_layer = Input(shape=image_inp_shape_conv)\n",
    "    conv_1 = Conv2D(filters=64, kernel_size=(2,2), activation='relu', padding='same')(input_layer)\n",
    "    flatten_1 = Flatten()(conv_1)\n",
    "    out_layer = Dense(no_of_labels, activation=\"softmax\")(flatten_1)\n",
    "    \n",
    "    model = Model(input_layer, out_layer)\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "#     model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def labels():\n",
    "    if os.path.isfile(labels_file_path):\n",
    "        labels_file = open(labels_file_path, \"r\")\n",
    "        labels = json.load(labels_file)\n",
    "    else:\n",
    "        labels_dict = {0:\"noise\"}\n",
    "        with open(labels_file_path, \"w\") as f:\n",
    "            json.dump(labels_dict, f)\n",
    "        labels = labels_dict\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    image_arr = cv2.imdecode(np.frombuffer(image, np.uint8), -1)\n",
    "    image_processed = cv2.resize(image_arr, image_inp_shape)\n",
    "    image_processed = cv2.cvtColor(image_processed, cv2.COLOR_BGR2GRAY)\n",
    "    image_processed = (image_processed) / 255.0\n",
    "    return image_processed\n",
    "\n",
    "def preprocess_gan(image):\n",
    "    image_arr = cv2.imdecode(np.frombuffer(image, np.uint8), -1)\n",
    "    image_processed = cv2.resize(image_arr, image_inp_shape)\n",
    "    image_processed = cv2.cvtColor(image_processed, cv2.COLOR_BGR2GRAY).reshape((dense_output,))\n",
    "    image_processed = (image_processed) / 255.0\n",
    "    return image_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image):\n",
    "    labels_read = labels()\n",
    "    if os.path.isfile(model_file):\n",
    "        model = load_model(model_file)\n",
    "    else:\n",
    "        model = req_model(no_of_labels=len(labels_read))\n",
    "    test_image = np.expand_dims(image, axis=0)\n",
    "    results = model.predict(test_image)\n",
    "    predicted_label = labels_read.get(str(np.argmax(results[0])))\n",
    "    return predicted_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model_arc(model_v1, model):\n",
    "#     model_v1 = req_model(no_of_labels=2)\n",
    "    for i in range(len(model_v1.layers) -1):\n",
    "        model_v1.layers[i].set_weights(model.layers[i].get_weights())\n",
    "\n",
    "    last_layer = model.layers[-1].get_weights()\n",
    "    temp_final_weights = []\n",
    "    labels_to_add = 1\n",
    "    for i in range(len(last_layer)):\n",
    "        if len(list(last_layer[i].shape)) > 1:\n",
    "            temp_dense = pad_sequences(last_layer[i], maxlen=last_layer[i].shape[-1] + labels_to_add, padding='post')\n",
    "        else:\n",
    "            temp_dense = np.pad(last_layer[i], pad_width=labels_to_add, mode='constant', constant_values=0)[\n",
    "                         labels_to_add:]\n",
    "        temp_final_weights.append(temp_dense)\n",
    "    model_v1.layers[-1].set_weights(temp_final_weights)\n",
    "    return model_v1\n",
    "\n",
    "def update_gan_arc(gen_v1, gen):\n",
    "#     gen_v1 = generator(n_classes=4)\n",
    "    for i in range(len(gen_v1.layers) -1):\n",
    "        if gen_v1.layers[i].get_config().get(\"name\") == \"embedding\":\n",
    "            last_layer = gen.get_layer(name=\"embedding\").get_weights()\n",
    "            temp_final_weights = []\n",
    "            labels_to_add = 1\n",
    "            for i in range(len(last_layer)):\n",
    "                temp_dense = needed_arr = np.random.rand(1,last_layer[i].shape[1])\n",
    "                temp_weights = np.concatenate((last_layer[i], temp_dense), axis=0)\n",
    "                temp_final_weights.append(temp_weights)\n",
    "            gen_v1.get_layer(name=\"embedding\").set_weights(temp_final_weights)\n",
    "        else:\n",
    "            gen_v1.layers[i].set_weights(gen.layers[i].get_weights())\n",
    "    return gen_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(image, ground_truth, add_label:bool):\n",
    "    labels_read = labels()\n",
    "    if os.path.isfile(model_file):\n",
    "        if add_label:\n",
    "            model_old = load_model(model_file)\n",
    "            model_new = req_model(no_of_labels=len(labels_read))\n",
    "            model = update_model_arc(model_v1=model_new, model=model_old)\n",
    "        else:\n",
    "            model = load_model(model_file)\n",
    "    else:\n",
    "        model = req_model(no_of_labels=len(labels_read))\n",
    "    test_image = np.expand_dims(image, axis=0)\n",
    "    ground_truth_arr = np.asarray([float(ground_truth)])\n",
    "    for i in tqdm(range(0,max_iter), desc=\"training req model...\"):\n",
    "        history = model.train_on_batch(test_image,ground_truth_arr)\n",
    "    model.save(\"model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(n_classes:int = None):\n",
    "    gen = Sequential()\n",
    "    gen.add(Dense(256,input_dim=latent_dim))\n",
    "    gen.add(LeakyReLU(0.2))\n",
    "    gen.add(BatchNormalization(momentum=0.8))\n",
    "    gen.add(Dense(512))\n",
    "    gen.add(LeakyReLU(0.2))\n",
    "    gen.add(BatchNormalization(momentum=0.8))\n",
    "    gen.add(Dense(1024))\n",
    "    gen.add(LeakyReLU(0.2))\n",
    "    gen.add(BatchNormalization(momentum=0.8))\n",
    "    gen.add(Dense(dense_output,activation='tanh'))\n",
    "\n",
    "    noise = Input(shape=(latent_dim,))\n",
    "    label = Input(shape=(1,),dtype='int32')\n",
    "    label_embedding = Flatten()(Embedding(n_classes,latent_dim, name=\"embedding\")(label))\n",
    "    model_input = multiply([noise,label_embedding])\n",
    "    image = gen(model_input)\n",
    "\n",
    "    gen = Model([noise,label],image)\n",
    "    gen.compile(loss='binary_crossentropy',optimizer='adam',metrics=[\"accuracy\"])\n",
    "    return gen\n",
    "\n",
    "\n",
    "def discriminator(n_classes:int = None):\n",
    "    disc = Sequential()\n",
    "    disc.add(Dense(512,input_dim=dense_output))\n",
    "    disc.add(LeakyReLU(0.2))\n",
    "    disc.add(Dropout(0.4))\n",
    "    disc.add(Dense(512))\n",
    "    disc.add(LeakyReLU(0.2))\n",
    "    disc.add(Dropout(0.4))\n",
    "    disc.add(Dense(512))\n",
    "    disc.add(LeakyReLU(0.2))\n",
    "    disc.add(Dropout(0.4))\n",
    "    disc.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "    image = Input(shape=(dense_output,))\n",
    "    label = Input(shape=(1,),dtype='int32')\n",
    "    label_embedding=Flatten()(Embedding(n_classes,dense_output)(label))\n",
    "    model_input=multiply([image,label_embedding])\n",
    "    prediction=disc(model_input)\n",
    "\n",
    "    disc = Model([image,label],prediction)\n",
    "    disc.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "    return disc\n",
    "\n",
    "\n",
    "def stacked_GAN(gen,disc):\n",
    "    gan_input = Input(shape=(latent_dim,))\n",
    "    label = Input(shape=(1,))\n",
    "    x = gen([gan_input,label])\n",
    "    disc.trainable=False\n",
    "    gan_out = disc([x,label])\n",
    "    gan_stack = Model([gan_input,label],gan_out)\n",
    "    gan_stack.compile(loss='binary_crossentropy',optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
    "    return gan_stack\n",
    "\n",
    "def test(gen, label_to_make,n_classes:int=None,i:int=None):\n",
    "    noise = np.random.normal(0,1,(1,latent_dim))\n",
    "    label = label_to_make\n",
    "    gen_image = np.squeeze(gen.predict([noise,label]),axis=0)\n",
    "#   plt.imsave('./epoch_%d_tag_%s'%(i,label[0]),image.reshape(image_inp_shape),format='jpg',cmap='gray')\n",
    "    return gen_image\n",
    "\n",
    "def train_cgan(max_iter,batch_size,gen,disc,gan_stack,X_train,y_train,n_classes:int=None,gen_model_path:str=None,disc_model_path:str=None):\n",
    "    valid=np.ones((batch_size,1))\n",
    "    fake=np.zeros((batch_size,1))\n",
    "    for i in tqdm(range(max_iter), desc=\"training cgan model...\"):\n",
    "        noise=np.random.normal(0,1,(batch_size,latent_dim))\n",
    "        index=np.random.randint(0, X_train.shape[0], size=batch_size)\n",
    "        image_batch = X_train[index]\n",
    "        label_batch = y_train[index]\n",
    "\n",
    "        fake_images=gen.predict([noise,label_batch])\n",
    "\n",
    "        disc.trainable=True\n",
    "        disc_loss_real=disc.train_on_batch([image_batch,label_batch],valid)\n",
    "        disc_loss_fake=disc.train_on_batch([fake_images,label_batch],fake)\n",
    "        disc_loss_final=0.5*np.add(disc_loss_real,disc_loss_fake)\n",
    "\n",
    "        fake_labels=np.random.randint(0,n_classes,batch_size).reshape(-1,1)\n",
    "        disc.trainable=False\n",
    "        gen_loss=gan_stack.train_on_batch([noise,fake_labels],valid)\n",
    "\n",
    "#       print('epoch_%d---->gen_loss:[%f]---->disc_loss:[%f]---->acc:[%f]'%(i,gen_loss,disc_loss_final[0],disc_loss_final[1]*100))\n",
    "        if i%100==0:\n",
    "            gen.save(gen_model_path)\n",
    "            disc.save(disc_model_path)\n",
    "#           test(gen,i, n_classes=n_classes, label_to_make=np.expand_dims(y_train, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper_train(image, ground_truth, add_label:bool):\n",
    "    latent_dim = 100\n",
    "    batch_size = 16\n",
    "    labels_read = labels()\n",
    "    test_image = np.expand_dims(image, axis=0)\n",
    "    ground_truth_arr = np.asarray([float(ground_truth)])\n",
    "    X_train, y_train, num_classes = test_image, ground_truth_arr, len(labels_read)\n",
    "\n",
    "    if os.path.isfile(gen_model_path):\n",
    "        if add_label:\n",
    "            gen_old = load_model(gen_model_path)\n",
    "            gen_new = generator(n_classes=num_classes)\n",
    "            gen = update_gan_arc(gen_v1=gen_new, gen=gen_old)\n",
    "        else:\n",
    "            gen = load_model(gen_model_path)\n",
    "    else:\n",
    "        gen = generator(n_classes=num_classes)\n",
    "\n",
    "    if os.path.isfile(disc_model_path):\n",
    "        if add_label:\n",
    "            disc_old = load_model(disc_model_path)\n",
    "            disc_new = discriminator(n_classes=num_classes)\n",
    "            disc = update_gan_arc(gen_v1=disc_new, gen=disc_old)\n",
    "        else:\n",
    "            disc = load_model(disc_model_path)\n",
    "    else:\n",
    "        disc = discriminator(n_classes=num_classes)\n",
    "\n",
    "    gan_stack = stacked_GAN(gen,disc)\n",
    "    train_cgan(max_iter,batch_size,gen,disc,gan_stack, n_classes=num_classes,\n",
    "               gen_model_path=gen_model_path, disc_model_path=disc_model_path,\n",
    "               X_train = X_train, y_train = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rev_labels(labels_dict):\n",
    "    rev_labels_read = {}\n",
    "    for key,val in labels_dict.items():\n",
    "        rev_labels_read[val] = key\n",
    "    return rev_labels_read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "feed the folder name:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./labels.json\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.4.0) /tmp/pip-req-build-vu_aq9yd/opencv/modules/imgproc/src/resize.cpp:3929: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-36e13b5b1855>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mimage_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mimage_arr_gan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_gan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfolder_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-c04b32b3287c>\u001b[0m in \u001b[0;36mpreprocess\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpreprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimage_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrombuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimage_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_inp_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mimage_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_processed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mimage_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage_processed\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.4.0) /tmp/pip-req-build-vu_aq9yd/opencv/modules/imgproc/src/resize.cpp:3929: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
     ]
    }
   ],
   "source": [
    "labels_file_path = \"./labels.json\"\n",
    "model_file = \"./model.h5\"\n",
    "gen_model_path = './generator.h5'\n",
    "disc_model_path = './discriminator.h5'\n",
    "image_inp_shape = (150,150)\n",
    "image_inp_shape_conv = (150,150,1)\n",
    "dense_output = int(image_inp_shape[0] * image_inp_shape[1])\n",
    "latent_dim = 100\n",
    "max_iter=200\n",
    "\n",
    "for i in range(0,5):\n",
    "    dataset_path = \".\"\n",
    "    folder_name = input(\"feed the folder name: \")\n",
    "    folder_path = os.path.join(dataset_path, folder_name)\n",
    "    image_path = os.path.join(folder_path, random.choice(os.listdir(folder_path)))\n",
    "    print(image_path)\n",
    "    image = open(image_path, \"rb\").read()\n",
    "    image_arr = preprocess(image=image)\n",
    "    image_arr_gan = preprocess_gan(image=image)\n",
    "    label = folder_name\n",
    "    prediction = predict(image=image_arr)\n",
    "    if prediction == label:\n",
    "        print(\"Rewarded\")\n",
    "    else:\n",
    "        if \"noise\" in list(labels().values()):\n",
    "            print(\"Punishment to remove noise\")\n",
    "            labels_read = {\"0\":label}\n",
    "            with open(labels_file_path, \"w\") as f:\n",
    "                json.dump(labels_read, f)\n",
    "            rev_labels_read=rev_labels(labels_dict=labels_read)\n",
    "            # TRAIN MODEL\n",
    "            train(image=image_arr, ground_truth=rev_labels_read.get(label),add_label=False)\n",
    "        else:\n",
    "            labels_read = labels()\n",
    "            rev_labels_read=rev_labels(labels_dict=labels_read)\n",
    "            if label in rev_labels_read:\n",
    "                print(\"Punishment to just retrain\")\n",
    "                \n",
    "                # TRAIN MODEL AND CGAN\n",
    "                train(image=image_arr, \n",
    "                      ground_truth=rev_labels_read.get(label),\n",
    "                      add_label=False)\n",
    "                \n",
    "                wrapper_train(image=image_arr_gan, \n",
    "                              ground_truth=rev_labels_read.get(label),\n",
    "                              add_label=False)\n",
    "                \n",
    "                for key,val in rev_labels_read.items():\n",
    "                    if key != label:\n",
    "                        gen = load_model(gen_model_path)\n",
    "                        label_to_send = np.expand_dims(np.asarray([float(rev_labels_read.get(key))]), axis=0)\n",
    "                        re_train_image = test(gen=gen, label_to_make=label_to_send)\n",
    "                        updated_image = re_train_image.reshape((image_inp_shape_conv))\n",
    "                        train(image=updated_image, \n",
    "                              ground_truth=rev_labels_read.get(key),\n",
    "                              add_label=False)\n",
    "            else:\n",
    "                print(\"Punishment to use cgan to remove bias\")\n",
    "                labels_read.update({len(labels_read):label})\n",
    "                with open(labels_file_path, \"w\") as f:\n",
    "                    json.dump(labels_read, f)\n",
    "                rev_labels_read=rev_labels(labels_dict=labels_read)\n",
    "                \n",
    "                # TRAIN THE MODEL AND CGAN WITH UPDATED ARC AND USE CGAN FOR REMOVING BIAS\n",
    "                train(image=image_arr, \n",
    "                      ground_truth=rev_labels_read.get(label), \n",
    "                      add_label=True)\n",
    "\n",
    "                wrapper_train(image=image_arr_gan, \n",
    "                              ground_truth=rev_labels_read.get(label), \n",
    "                              add_label=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"/forest/10736.jpg\"\n",
    "image = open(image_path, \"rb\")\n",
    "image_arr = preprocess(image=image.read())\n",
    "label = folder_name\n",
    "prediction = predict(image=image_arr)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
