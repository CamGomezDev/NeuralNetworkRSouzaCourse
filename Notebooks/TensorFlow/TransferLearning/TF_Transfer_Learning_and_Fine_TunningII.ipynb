{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification: Dogs vs. Cats Competition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example shows how to implement a transfer learning solution to solve image classification problems. Data from the \n",
    "[Dogs vs. Cats](https://www.kaggle.com/c/dogs-vs-cats) Kaggle competition is used in this example. \n",
    "\n",
    "The goal of this competition is to build a model that identifies which animal - dog or cat - is in the image. Accordingly, it is a binary classification problem (1=dog, 0=cat). The training data contains 25 000 labeled images of dogs and cats.\n",
    "\n",
    "Several parts of this example were based on [Deep Learning with Python](https://amzn.to/2CeEySF). Other important references are [Lin et al. (2013)](https://arxiv.org/pdf/1312.4400.pdf) and [Tang (2013)](https://arxiv.org/pdf/1306.0239.pdf), which were used to develop the global average pooling and the linear support vector machines solutions, respectively.\n",
    "\n",
    "**Dataset**\n",
    "* Inputs: Images of dogs and cats.\n",
    "* Outputs: Classification labels (1=dog, 0=cat).\n",
    "* You can download the original dataset from this [link](https://www.kaggle.com/c/dogs-vs-cats/data).\n",
    "\n",
    "**Error metric**\n",
    "* Percentage of correctly labeled images (accuracy). \n",
    "* This error metric is defined by [Kaggle](https://www.kaggle.com/c/dogs-vs-cats#evaluation).\n",
    "\n",
    "**Evaluation protocol**\n",
    "* Fully-connected layers: Hold-out validation. \n",
    "* Global average pooling: Hold-out validation.\n",
    "* Support vector machines: K-fold cross-validation.\n",
    "\n",
    "**Performance goals**\n",
    "* Accuracy > 0.85\n",
    "\n",
    "**Solutions**\n",
    "1. [Fully-connected layers](#1.-Fully-connected-layers)\n",
    "1. [Global average pooling](#2.-Global-average-pooling)\n",
    "1. [Linear support vector machines](#3.-Linear-support-vector-machines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Fully-connected layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I mentioned before, the dataset has 25 000 images of dogs and cats (12 500 from each class). This is a large dataset, which will hardly run on my computer. Accordingly, I will create a shorter dataset to build my model. This dataset will contain three subsets:\n",
    "1. Training set with 200 samples of each class.\n",
    "1. Validation set with 100 samples of each class.\n",
    "1. Test set with 100 samples of each class.\n",
    "\n",
    "To create this new dataset I used the script *import_dogs_cats.py*, which is based on [Chollet's book](https://amzn.to/2NEqnIH). The results achieved in this exercise would be much better if a larger dataset was used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: './dogs_cats/data'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Documents\\Repos\\NeuralNetworks_Course\\Notebooks\\TensorFlow\\TransferLearning\\import_dogs_cats.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mbase_dir\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'./dogs_cats/data'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m# Create directories\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: './dogs_cats/data'"
     ]
    }
   ],
   "source": [
    "# Create new dataset\n",
    "#%run ./import_dogs_cats.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have a balanced dataset with:\n",
    "* 200 training images (100 cats + 100 dogs).\n",
    "* 100 validation images (50 cats + 50 dogs).\n",
    "* 100 test images (50 cats + 50 dogs).\n",
    "\n",
    "Indeed, an economic dataset. \n",
    "\n",
    "Let's display some pictures to see if everything looks ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base variables\n",
    "base_dir = '/Data'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "validation_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "train_cats_dir = os.path.join(train_dir, 'cats')\n",
    "train_dogs_dir = os.path.join(train_dir, 'dogs')\n",
    "\n",
    "train_size, validation_size, test_size = 200, 100, 100\n",
    "\n",
    "img_width, img_height = 224, 224  # Default input size for VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: '/Data\\\\train\\\\cats'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-fa653d97fba9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mshow_pictures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_cats_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mshow_pictures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dogs_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-fa653d97fba9>\u001b[0m in \u001b[0;36mshow_pictures\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mshow_pictures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mrandom_img\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mimg_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_img\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: '/Data\\\\train\\\\cats'"
     ]
    }
   ],
   "source": [
    "# Show pictures\n",
    "import os, random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "def show_pictures(path):\n",
    "    random_img = random.choice(os.listdir(path))\n",
    "    img_path = os.path.join(path, random_img)\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(img_width, img_height))\n",
    "    img_tensor = image.img_to_array(img)  # Image data encoded as integers in the 0â€“255 range\n",
    "    img_tensor /= 255.  # Normalize to [0,1] for plt.imshow application\n",
    "    plt.imshow(img_tensor)\n",
    "    plt.show()\n",
    "    \n",
    "for i in range(0,2):\n",
    "    show_pictures(train_cats_dir)\n",
    "    show_pictures(train_dogs_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set of lovely dogs and cats. Everything seems to be working as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we want to use a solution based on pre-trained models. We will use models that are composed of two parts:\n",
    "* Convolutional base.\n",
    "* Classifier.\n",
    "\n",
    "Our approach will use the convolutional base to extract features, using them to train a classifier to classify the input image as dog or cat. Therefore, the features extracted from the convolutional base will be the same for all classifiers studied in this example.\n",
    "\n",
    "Now let's see how to extract features from a convolutional base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate convolutional base\n",
    "from keras.applications import VGG16\n",
    "\n",
    "conv_base = VGG16(weights='imagenet', \n",
    "                  include_top=False,\n",
    "                  input_shape=(img_width, img_height, 3))  # 3 = number of channels in RGB pictures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Line by line, what we are doing in VGG16 is:\n",
    "* **weights** initializes model's weights. Here we are saying that we want to use the same weights as [ImageNet](http://www.image-net.org/). This is smart because we know that our dataset is similar to the ImageNet dataset (i.e. it has dogs and cats).\n",
    "* **include_top** as false means that we want to train our own classifier on top of the convolutional base. The original VGG16 classifies images according to a set of 1 000 possible classes. Here we are just classifying our images as 'dogs' or 'cats'. \n",
    "* **input_shape** defines the shape of the image tensors that will feed the network. We used the default input size of VGG16 (224x224), but we could have used a different shape. For example, [Chollet](https://amzn.to/2pU8OuM) uses 150x150.\n",
    "\n",
    "We can now check the architecture of the convolutional base that we instantiated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check architecture\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, now that we have the convolutional base, we need to pass our images through it for feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features\n",
    "import os, shutil\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255)\n",
    "batch_size = 32\n",
    "\n",
    "def extract_features(directory, sample_count):\n",
    "    features = np.zeros(shape=(sample_count, 7, 7, 512))  # Must be equal to the output of the convolutional base\n",
    "    labels = np.zeros(shape=(sample_count))\n",
    "    # Preprocess data\n",
    "    generator = datagen.flow_from_directory(directory,\n",
    "                                            target_size=(img_width,img_height),\n",
    "                                            batch_size = batch_size,\n",
    "                                            class_mode='binary')\n",
    "    # Pass data through convolutional base\n",
    "    i = 0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = conv_base.predict(inputs_batch)\n",
    "        features[i * batch_size: (i + 1) * batch_size] = features_batch\n",
    "        labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n",
    "        i += 1\n",
    "        if i * batch_size >= sample_count:\n",
    "            break\n",
    "    return features, labels\n",
    "    \n",
    "train_features, train_labels = extract_features(train_dir, train_size)  # Agree with our small dataset size\n",
    "validation_features, validation_labels = extract_features(validation_dir, validation_size)\n",
    "test_features, test_labels = extract_features(test_dir, test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code above, we used *flow_from_directory*. When we use this method, the labels are inferred from the directory structure. This is an important detail to understand the code. For further details on how *flow_from_directory* works, I recommend you to read this [blog post](https://towardsdatascience.com/keras-a-thing-you-should-know-about-keras-if-you-plan-to-train-a-deep-learning-model-on-a-large-fdd63ce66bd2).\n",
    "\n",
    "Let's just do a quick debug to see if everything is ok."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debug\n",
    "print(train_features)\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, looks nice. Each sample has a wide range of features and labels are 0 or 1.\n",
    "\n",
    "Now that we have the features, we can use any of the three classifiers that we suggest in this example. Accordingly, on top of our convolutional base, we will add a classifier and then our model is ready to make predictions.\n",
    "\n",
    "In the next section, we will solve the problem using the most common solution: fully-connected layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2. Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will see how to build a classifier based on fully-connected layers. This classifier will use the features extracted from the convolutional base.\n",
    "\n",
    "There are several models possible. You can add more layers, more neurons, use different optimizers, or any other modification. To keep it simple (and fast), we will use the solution proposed by Chollet in his [book](https://amzn.to/2pU8OuM) with slight variations. In particular, we will use the Adam optimizer instead of the RMSProp because [Stanford says so](http://cs231n.github.io/neural-networks-3/#adam) (what a beautiful *argumentum ad verecundiam*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Flatten(input_shape=(7,7,512)))\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=(7*7*512)))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=optimizers.Adam(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size, \n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('dogs_cat_fcl.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model evaluation is an essential part of the work because it allows you to see how your solution is performing. Often, you'll find bugs in your code during this step, as well as ideas on how to improve your model.\n",
    "\n",
    "Here, we will not go much into detail. Accordingly, we will just check the [learning curves](http://pmarcelino.com/how-to-read-learning-curves-and-why-do-we-need-them-in-deep-learning/) and visualize the model in action  for a random set of pictures. If you want to know more about the subject, you can read the [Practical Methodology](https://www.deeplearningbook.org/contents/guidelines.html) chapter of [Deep Learning](https://amzn.to/2RLcdJ0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to visualize predictions\n",
    "def visualize_predictions(classifier, n_cases):\n",
    "    for i in range(0,n_cases):\n",
    "        path = random.choice([test_cats_dir, test_dogs_dir])\n",
    "\n",
    "        # Get picture\n",
    "        random_img = random.choice(os.listdir(path))\n",
    "        img_path = os.path.join(path, random_img)\n",
    "        img = image.load_img(img_path, target_size=(img_width, img_height))\n",
    "        img_tensor = image.img_to_array(img)  # Image data encoded as integers in the 0â€“255 range\n",
    "        img_tensor /= 255.  # Normalize to [0,1] for plt.imshow application\n",
    "\n",
    "        # Extract features\n",
    "        features = conv_base.predict(img_tensor.reshape(1,img_width, img_height, 3))\n",
    "\n",
    "        # Make prediction\n",
    "        try:\n",
    "            prediction = classifier.predict(features)\n",
    "        except:\n",
    "            prediction = classifier.predict(features.reshape(1, 7*7*512))\n",
    "\n",
    "        # Show picture\n",
    "        plt.imshow(img_tensor)\n",
    "        plt.show()\n",
    "\n",
    "        # Write prediction\n",
    "        if prediction < 0.5:\n",
    "            print('Cat')\n",
    "        else:\n",
    "            print('Dog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "visualize_predictions(model, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "* Validation accuracy is around 0.85, which barely achieves our performance goals.\n",
    "* The model strongly overfits. There's a big gap between the training and the validation curves.\n",
    "* Since we already used dropout, we should increase the size of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Global average pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we don't need to preprocess the data. We will just use the features extracted from the convolutional base to feed the classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference between this case and the previous one is that, instead of adding a stack of fully-connected layers, we will add a global average pooling layer and fed its output into a sigmoid activated layer.\n",
    "\n",
    "Note that we are talking about a sigmoid activated layers instead of a softmax one, which is what is recommended by [Lin et al. (2013)](https://arxiv.org/pdf/1312.4400.pdf). We are changing to the sigmoid activation because in Keras, to perform binary classification, you should use *sigmoid* activation and *binary_crossentropy* as the loss (see [Chollet's book](https://amzn.to/2Cdza25)). Accordingly, it was necessary to do this small modification to the original proposal of [Lin et al. (2013)](https://arxiv.org/pdf/1312.4400.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model\n",
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "epochs = 100\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.GlobalAveragePooling2D(input_shape=(7,7,512)))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "model.compile(optimizer=optimizers.Adam(),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=batch_size, \n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('dogs_cat_gap.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model in action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "visualize_predictions(model, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "* Validation accuracy is similar to the one resulting from the fully-connected layers solution.\n",
    "* The model doesn't overfit as much as in the previous case.\n",
    "* Training and validation loss have higher values than in the fully-connected model.\n",
    "* It seems that the model could benefit from some training more (increase the number of epochs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Linear support vector machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we will train a linear SVM classifier on the features extracted by the convolutional base. To train this classifier, a traditional machine learning approach is preferable. Accordingly, we will use k-fold cross-validation to estimate the error of the classifier. Since k-fold cross-validation will be used, we can concatenate the train and the validation sets to enlarge our training data (we keep the test set untouched, as we did in the previous cases)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate training and validation sets\n",
    "svm_features = np.concatenate((train_features, validation_features))\n",
    "svm_labels = np.concatenate((train_labels, validation_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SVM classifier has one hyperparameter. This hyperparameter is the penalty parameter C of the error term. To optimize the choice of this hyperparameter, we will use [exhaustive grid search](http://scikit-learn.org/stable/modules/grid_search.html#grid-search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build model\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "X_train, y_train = svm_features.reshape(300,7*7*512), svm_labels\n",
    "\n",
    "param = [{\n",
    "          \"C\": [0.01, 0.1, 1, 10, 100]\n",
    "         }]\n",
    " \n",
    "svm = LinearSVC(penalty='l2', loss='squared_hinge')  # As in Tang (2013)\n",
    "clf = GridSearchCV(svm, param, cv=10)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('dogs_cat_svm.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"\\nAccuracy score (mean):\")\n",
    "print(np.mean(cross_val_score(clf, X_train, y_train, cv=10)))\n",
    "print(\"\\nAccuracy score (standard deviation):\")\n",
    "print(np.std(cross_val_score(clf, X_train, y_train, cv=10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves\n",
    "from sklearn.model_selection import learning_curve\n",
    "'''\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator = clf,\n",
    "                                                        X = X_train,\n",
    "                                                        y = y_train,\n",
    "                                                        train_sizes = np.linspace(0.1,1.0,10),\n",
    "                                                        cv = 10)\n",
    "'''\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean, color='blue', \n",
    "         marker='o', markersize=5, label='Training accuracy')\n",
    "plt.fill_between(train_sizes,\n",
    "                 train_mean + train_std,\n",
    "                 train_mean - train_std,\n",
    "                 alpha=0.15, color='blue')\n",
    "\n",
    "\n",
    "plt.plot(train_sizes, test_mean, color='green', linestyle='--',\n",
    "         marker='s', markersize=5, label='Validation accuracy')\n",
    "plt.fill_between(train_sizes,\n",
    "                 test_mean + test_std,\n",
    "                 test_mean - test_std,\n",
    "                 alpha=0.15, color='green')\n",
    "plt.grid()\n",
    "plt.xlabel('Number of training samples')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.ylim([0.5, 1.1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions\n",
    "visualize_predictions(clf, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comments**\n",
    "* Model's accuracy is around 0.86, which is similar to the accuracy of the previous solutions.\n",
    "* Overfitting is around the corner. Moreover, the training accuracy is always 1.0, which is not usual and can be interpreted as a sign of overfitting. \n",
    "* The accuracy of the model should increase with the number of training samples. However, that doesn't seem to happen. This may be due to overfitting. It would be interesting to see how the model reacts when the dataset increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we:\n",
    "* Showed how to use transfer learning to solve image classification problems.\n",
    "* Used a pre-trained convolutional neural network model to extract features from pictures.\n",
    "* Fed those features into different classifiers to build a prediction model.\n",
    "* Tested classifiers based on fully-connected layers, global average pooling, and linear support vector machines."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
