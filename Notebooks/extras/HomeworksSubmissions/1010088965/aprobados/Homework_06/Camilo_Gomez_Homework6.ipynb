{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 6\n",
    "* classify mnist_test.csv dataset\n",
    "* what is the highest validation set accuracy you get (95%...?)\n",
    "  * consider normalizing the data\n",
    "  * changing optimizer (sgd,rmsprop,adam)...\n",
    "  * number of epochs\n",
    "  * structure of the Neural Network (number of neurons)\n",
    "  * you can convert the labels to one-hot\n",
    "* remember to fix the randomizer (maybe with the same number as I have here for comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the basic modules and the dataset are loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist_test = pd.read_csv(\"mnist_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now a little sample of the images with their respective correct digits are shown:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_data = mnist_test.iloc[:,1:].to_numpy().reshape((10000, 28, 28))\n",
    "y_data = mnist_test[\"label\"].to_numpy()\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "random_imgs_idx = np.random.randint(0,10000,(25))\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        plt.subplot(3,3,i*3 + j + 1)\n",
    "        plt.title(\"Digit: \" + str(y_data[random_imgs_idx[i*5 + j]]))\n",
    "        plt.imshow(X_data[random_imgs_idx[i*5 + j]], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, a variety of options will be considered to check which one generates the most accurate predictions on the test data:\n",
    "- Data normalized and not normalized\n",
    "- 8 and 16 neurons in the middle layer\n",
    "- One-hot encoding and numerical encoding\n",
    "- Optimizer RMSProp and Adam\n",
    "- 16 and 32 epochs\n",
    "\n",
    "These are 5 hyperparameters to check, each one with two alternatives, and if all of the possible combinations are to be checked, this would mean that there will be $2^5=32$ models in total.\n",
    "\n",
    "Now the model classes will be imported and a seed will be used:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import InputLayer, Dense, Flatten\n",
    "from tensorflow import one_hot\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "tf.random.set_seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the individual hyperparms will have their own function so they can be called when the hyperparams search is being performed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = mnist_test.iloc[:,1:].to_numpy()\n",
    "y_data = mnist_test[\"label\"].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data,test_size = 0.2)\n",
    "\n",
    "def get_X_train_test(norm_type):\n",
    "    if norm_type == \"normalized\":\n",
    "        X_train_used = X_train/255.\n",
    "        X_test_used = X_test/255.\n",
    "    elif norm_type == \"not_normalized\":\n",
    "        X_train_used = X_train\n",
    "        X_test_used = X_test\n",
    "\n",
    "    return X_train_used, X_test_used\n",
    "\n",
    "def get_y_train_test_and_loss(encoding):\n",
    "    if encoding == \"one_hot\":\n",
    "        y_train_used = one_hot(y_train, depth=10)\n",
    "        y_test_used = one_hot(y_test, depth=10)\n",
    "        loss_used = \"categorical_crossentropy\"\n",
    "    elif encoding == \"numerical\":\n",
    "        y_train_used = y_train\n",
    "        y_test_used = y_test\n",
    "        loss_used = \"sparse_categorical_crossentropy\"\n",
    "    \n",
    "    return y_train_used, y_test_used, loss_used\n",
    "\n",
    "def get_model(neurons_middle_layer):\n",
    "    model = Sequential([\n",
    "        InputLayer(input_shape=X_train[0].shape),\n",
    "        Dense(units=neurons_middle_layer, activation='relu', name='layer_hidden'),\n",
    "        Dense(units=10, activation='softmax', name='output_layer')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def compile_model(model, optimizer_used, loss_f):\n",
    "    model.compile(\n",
    "        optimizer=optimizer_used,\n",
    "        loss=loss_f,\n",
    "        metrics=['accuracy']\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And to create all of the possible alternatives, a `for` loop will be used, with all of the individual hyperparams having their own functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 776us/step - loss: 0.3867 - accuracy: 0.8920\n",
      "For these params: \n",
      "    Normalization:  normalized\n",
      "    Neurons of middle layer:  8\n",
      "    Encoding:  one_hot\n",
      "    Optimizer:  rmsprop\n",
      "    No. Epochs:  16\n",
      "The accuracy is  0.8920000195503235\n",
      "63/63 [==============================] - 0s 777us/step - loss: 0.3181 - accuracy: 0.9115\n",
      "For these params: \n",
      "    Normalization:  normalized\n",
      "    Neurons of middle layer:  8\n",
      "    Encoding:  one_hot\n",
      "    Optimizer:  rmsprop\n",
      "    No. Epochs:  32\n",
      "The accuracy is  0.9114999771118164\n",
      "63/63 [==============================] - 0s 740us/step - loss: 0.3363 - accuracy: 0.9015\n",
      "For these params: \n",
      "    Normalization:  normalized\n",
      "    Neurons of middle layer:  8\n",
      "    Encoding:  one_hot\n",
      "    Optimizer:  adam\n",
      "    No. Epochs:  16\n",
      "The accuracy is  0.9014999866485596\n",
      "63/63 [==============================] - 0s 759us/step - loss: 0.3487 - accuracy: 0.9045\n",
      "For these params: \n",
      "    Normalization:  normalized\n",
      "    Neurons of middle layer:  8\n",
      "    Encoding:  one_hot\n",
      "    Optimizer:  adam\n",
      "    No. Epochs:  32\n",
      "The accuracy is  0.9045000076293945\n",
      "63/63 [==============================] - 0s 934us/step - loss: 0.3763 - accuracy: 0.8955\n",
      "For these params: \n",
      "    Normalization:  normalized\n",
      "    Neurons of middle layer:  8\n",
      "    Encoding:  numerical\n",
      "    Optimizer:  rmsprop\n",
      "    No. Epochs:  16\n",
      "The accuracy is  0.8955000042915344\n",
      "63/63 [==============================] - 0s 930us/step - loss: 0.3433 - accuracy: 0.9130\n",
      "For these params: \n",
      "    Normalization:  normalized\n",
      "    Neurons of middle layer:  8\n",
      "    Encoding:  numerical\n",
      "    Optimizer:  rmsprop\n",
      "    No. Epochs:  32\n",
      "The accuracy is  0.9129999876022339\n",
      "63/63 [==============================] - 0s 771us/step - loss: 0.3220 - accuracy: 0.9020\n",
      "For these params: \n",
      "    Normalization:  normalized\n",
      "    Neurons of middle layer:  8\n",
      "    Encoding:  numerical\n",
      "    Optimizer:  adam\n",
      "    No. Epochs:  16\n",
      "The accuracy is  0.9020000100135803\n",
      "63/63 [==============================] - 0s 747us/step - loss: 0.3272 - accuracy: 0.9115\n",
      "For these params: \n",
      "    Normalization:  normalized\n",
      "    Neurons of middle layer:  8\n",
      "    Encoding:  numerical\n",
      "    Optimizer:  adam\n",
      "    No. Epochs:  32\n",
      "The accuracy is  0.9114999771118164\n",
      "63/63 [==============================] - 0s 771us/step - loss: 0.2695 - accuracy: 0.9260\n",
      "For these params: \n",
      "    Normalization:  normalized\n",
      "    Neurons of middle layer:  16\n",
      "    Encoding:  one_hot\n",
      "    Optimizer:  rmsprop\n",
      "    No. Epochs:  16\n",
      "The accuracy is  0.9259999990463257\n",
      "63/63 [==============================] - 0s 772us/step - loss: 0.2956 - accuracy: 0.9275\n",
      "For these params: \n",
      "    Normalization:  normalized\n",
      "    Neurons of middle layer:  16\n",
      "    Encoding:  one_hot\n",
      "    Optimizer:  rmsprop\n",
      "    No. Epochs:  32\n",
      "The accuracy is  0.9275000095367432\n",
      "63/63 [==============================] - 0s 764us/step - loss: 0.2584 - accuracy: 0.9240\n",
      "For these params: \n",
      "    Normalization:  normalized\n",
      "    Neurons of middle layer:  16\n",
      "    Encoding:  one_hot\n",
      "    Optimizer:  adam\n",
      "    No. Epochs:  16\n",
      "The accuracy is  0.9240000247955322\n",
      "63/63 [==============================] - 0s 747us/step - loss: 0.2998 - accuracy: 0.9275\n",
      "For these params: \n",
      "    Normalization:  normalized\n",
      "    Neurons of middle layer:  16\n",
      "    Encoding:  one_hot\n",
      "    Optimizer:  adam\n",
      "    No. Epochs:  32\n",
      "The accuracy is  0.9275000095367432\n",
      "63/63 [==============================] - 0s 777us/step - loss: 0.2662 - accuracy: 0.9260\n",
      "For these params: \n",
      "    Normalization:  normalized\n",
      "    Neurons of middle layer:  16\n",
      "    Encoding:  numerical\n",
      "    Optimizer:  rmsprop\n",
      "    No. Epochs:  16\n",
      "The accuracy is  0.9259999990463257\n",
      "63/63 [==============================] - 0s 830us/step - loss: 0.2847 - accuracy: 0.9280\n",
      "For these params: \n",
      "    Normalization:  normalized\n",
      "    Neurons of middle layer:  16\n",
      "    Encoding:  numerical\n",
      "    Optimizer:  rmsprop\n",
      "    No. Epochs:  32\n",
      "The accuracy is  0.9279999732971191\n",
      "63/63 [==============================] - 0s 730us/step - loss: 0.2521 - accuracy: 0.9280\n",
      "For these params: \n",
      "    Normalization:  normalized\n",
      "    Neurons of middle layer:  16\n",
      "    Encoding:  numerical\n",
      "    Optimizer:  adam\n",
      "    No. Epochs:  16\n",
      "The accuracy is  0.9279999732971191\n",
      "63/63 [==============================] - 0s 766us/step - loss: 0.3228 - accuracy: 0.9215\n",
      "For these params: \n",
      "    Normalization:  normalized\n",
      "    Neurons of middle layer:  16\n",
      "    Encoding:  numerical\n",
      "    Optimizer:  adam\n",
      "    No. Epochs:  32\n",
      "The accuracy is  0.921500027179718\n",
      "63/63 [==============================] - 0s 769us/step - loss: 1.7672 - accuracy: 0.4370\n",
      "For these params: \n",
      "    Normalization:  not_normalized\n",
      "    Neurons of middle layer:  8\n",
      "    Encoding:  one_hot\n",
      "    Optimizer:  rmsprop\n",
      "    No. Epochs:  16\n",
      "The accuracy is  0.43700000643730164\n",
      "63/63 [==============================] - 0s 773us/step - loss: 2.2044 - accuracy: 0.2865\n",
      "For these params: \n",
      "    Normalization:  not_normalized\n",
      "    Neurons of middle layer:  8\n",
      "    Encoding:  one_hot\n",
      "    Optimizer:  rmsprop\n",
      "    No. Epochs:  32\n",
      "The accuracy is  0.2865000069141388\n",
      "63/63 [==============================] - 0s 762us/step - loss: 2.3026 - accuracy: 0.1105\n",
      "For these params: \n",
      "    Normalization:  not_normalized\n",
      "    Neurons of middle layer:  8\n",
      "    Encoding:  one_hot\n",
      "    Optimizer:  adam\n",
      "    No. Epochs:  16\n",
      "The accuracy is  0.11050000041723251\n",
      "63/63 [==============================] - 0s 751us/step - loss: 1.3329 - accuracy: 0.6480\n",
      "For these params: \n",
      "    Normalization:  not_normalized\n",
      "    Neurons of middle layer:  8\n",
      "    Encoding:  one_hot\n",
      "    Optimizer:  adam\n",
      "    No. Epochs:  32\n",
      "The accuracy is  0.6480000019073486\n",
      "63/63 [==============================] - 0s 750us/step - loss: 1.9781 - accuracy: 0.3575\n",
      "For these params: \n",
      "    Normalization:  not_normalized\n",
      "    Neurons of middle layer:  8\n",
      "    Encoding:  numerical\n",
      "    Optimizer:  rmsprop\n",
      "    No. Epochs:  16\n",
      "The accuracy is  0.35749998688697815\n",
      "63/63 [==============================] - 0s 757us/step - loss: 1.9814 - accuracy: 0.3995\n",
      "For these params: \n",
      "    Normalization:  not_normalized\n",
      "    Neurons of middle layer:  8\n",
      "    Encoding:  numerical\n",
      "    Optimizer:  rmsprop\n",
      "    No. Epochs:  32\n",
      "The accuracy is  0.3995000123977661\n",
      "63/63 [==============================] - 0s 794us/step - loss: 1.7674 - accuracy: 0.5605\n",
      "For these params: \n",
      "    Normalization:  not_normalized\n",
      "    Neurons of middle layer:  8\n",
      "    Encoding:  numerical\n",
      "    Optimizer:  adam\n",
      "    No. Epochs:  16\n",
      "The accuracy is  0.5605000257492065\n",
      "63/63 [==============================] - 0s 766us/step - loss: 1.4980 - accuracy: 0.6015\n",
      "For these params: \n",
      "    Normalization:  not_normalized\n",
      "    Neurons of middle layer:  8\n",
      "    Encoding:  numerical\n",
      "    Optimizer:  adam\n",
      "    No. Epochs:  32\n",
      "The accuracy is  0.6014999747276306\n",
      "63/63 [==============================] - 0s 875us/step - loss: 1.7429 - accuracy: 0.4095\n",
      "For these params: \n",
      "    Normalization:  not_normalized\n",
      "    Neurons of middle layer:  16\n",
      "    Encoding:  one_hot\n",
      "    Optimizer:  rmsprop\n",
      "    No. Epochs:  16\n",
      "The accuracy is  0.40950000286102295\n",
      "63/63 [==============================] - 0s 806us/step - loss: 1.9209 - accuracy: 0.6925\n",
      "For these params: \n",
      "    Normalization:  not_normalized\n",
      "    Neurons of middle layer:  16\n",
      "    Encoding:  one_hot\n",
      "    Optimizer:  rmsprop\n",
      "    No. Epochs:  32\n",
      "The accuracy is  0.6924999952316284\n",
      "63/63 [==============================] - 0s 807us/step - loss: 1.0224 - accuracy: 0.8160\n",
      "For these params: \n",
      "    Normalization:  not_normalized\n",
      "    Neurons of middle layer:  16\n",
      "    Encoding:  one_hot\n",
      "    Optimizer:  adam\n",
      "    No. Epochs:  16\n",
      "The accuracy is  0.8159999847412109\n",
      "63/63 [==============================] - 0s 832us/step - loss: 1.4897 - accuracy: 0.4155\n",
      "For these params: \n",
      "    Normalization:  not_normalized\n",
      "    Neurons of middle layer:  16\n",
      "    Encoding:  one_hot\n",
      "    Optimizer:  adam\n",
      "    No. Epochs:  32\n",
      "The accuracy is  0.4154999852180481\n",
      "63/63 [==============================] - 0s 964us/step - loss: 1.9060 - accuracy: 0.7770\n",
      "For these params: \n",
      "    Normalization:  not_normalized\n",
      "    Neurons of middle layer:  16\n",
      "    Encoding:  numerical\n",
      "    Optimizer:  rmsprop\n",
      "    No. Epochs:  16\n",
      "The accuracy is  0.7770000100135803\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.9407 - accuracy: 0.5570\n",
      "For these params: \n",
      "    Normalization:  not_normalized\n",
      "    Neurons of middle layer:  16\n",
      "    Encoding:  numerical\n",
      "    Optimizer:  rmsprop\n",
      "    No. Epochs:  32\n",
      "The accuracy is  0.5569999814033508\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 0s 830us/step - loss: 1.8145 - accuracy: 0.3675\n",
      "For these params: \n",
      "    Normalization:  not_normalized\n",
      "    Neurons of middle layer:  16\n",
      "    Encoding:  numerical\n",
      "    Optimizer:  adam\n",
      "    No. Epochs:  16\n",
      "The accuracy is  0.3675000071525574\n",
      "63/63 [==============================] - 0s 1ms/step - loss: 1.2872 - accuracy: 0.7710\n",
      "For these params: \n",
      "    Normalization:  not_normalized\n",
      "    Neurons of middle layer:  16\n",
      "    Encoding:  numerical\n",
      "    Optimizer:  adam\n",
      "    No. Epochs:  32\n",
      "The accuracy is  0.7710000276565552\n"
     ]
    }
   ],
   "source": [
    "for normalized in [\"normalized\", \"not_normalized\"]:\n",
    "    for neurons_middle_layer in [8, 16]:\n",
    "        for encoding in [\"one_hot\", \"numerical\"]:\n",
    "            for optimizer in [\"rmsprop\", \"adam\"]:\n",
    "                for no_epochs in [16, 32]:\n",
    "                    X_train_used, X_test_used = get_X_train_test(normalized)\n",
    "                    model = get_model(neurons_middle_layer)\n",
    "                    y_train_used, y_test_used, loss_used = get_y_train_test_and_loss(encoding)\n",
    "                    compile_model(model, optimizer, loss_used)\n",
    "                    model.fit(X_train_used, y_train_used, epochs=no_epochs, verbose=0)\n",
    "                    loss, accuracy = model.evaluate(X_test_used, y_test_used)\n",
    "                    print(\"For these params: \")\n",
    "                    print(\"    Normalization: \", normalized)\n",
    "                    print(\"    Neurons of middle layer: \", neurons_middle_layer)\n",
    "                    print(\"    Encoding: \", encoding)\n",
    "                    print(\"    Optimizer: \", optimizer)\n",
    "                    print(\"    No. Epochs: \", no_epochs)\n",
    "                    print(\"The accuracy is \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in the results, the largest accuracy achieved in the test set has been of 93.4%, which has been achieved by a model with these parameters:\n",
    "\n",
    "- Normalization:  normalized\n",
    "- Neurons of middle layer:  16\n",
    "- Encoding:  one_hot\n",
    "- Optimizer:  rmsprop\n",
    "- No. Epochs:  32\n",
    "\n",
    "Something interesting to notice is that the parameter that drops the accuracy the most by far is having the data not normalized. The other params give a good result with either of their two options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1fa65432bd728bfafdd5725ebe357acdb166fde821238c9f428dcfd1a12586b6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
