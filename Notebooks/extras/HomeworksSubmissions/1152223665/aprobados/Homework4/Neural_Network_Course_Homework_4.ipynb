{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a7l8qVnl1HyO"
   },
   "source": [
    "# **Samuel Vasco Vasco González**  Cc. 1152223665"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CMj-yM6_aj6l",
    "outputId": "02fbcc35-7324-4742-9362-d497c43f8734"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HTvaEWiuc3rz",
    "outputId": "b10783ba-3818-4855-be5e-e39702c7f513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tabulate'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-87c82d19e595>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_absolute_percentage_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtabulate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtabulate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tabulate'"
     ]
    }
   ],
   "source": [
    "#lybraries\n",
    "%pylab inline\n",
    "import pandas as pd\n",
    "from mpl_toolkits import mplot3d\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 626
    },
    "id": "pkLYQwmsc6gD",
    "outputId": "a3f9b259-d442-476d-8e38-299f601dcdd9"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"uelConsumption.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8aeYSxY_3ty"
   },
   "source": [
    "Este data set contiene el índice de consumo de combustible de modelos específicos y un estimado de las emisiones de Dióxido de carbono para vehículos ligeros nuevos para la venta al por menor en Canadá."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "ckaL9LQNuuaK",
    "outputId": "22200394-e7a6-4c53-9bac-986e50922911"
   },
   "outputs": [],
   "source": [
    "data_extract=data[['CO2EMISSIONS','ENGINESIZE','CYLINDERS','FUELCONSUMPTION_CITY','FUELCONSUMPTION_HWY','FUELCONSUMPTION_COMB']]\n",
    "data_extract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "48oqcxseAa36"
   },
   "source": [
    "Una vez seleccionadas estas características, implementaremos un modelo de regresión lineal que busca predecir las emisiones de CO2 (CO2EMISSIONS) a partir de características o predictores como el tamaño del motor (ENGINESIZE), el número de cilindros (CYLINDERS), consumo de gasolina en la ciudad (FUELCONSUMPTION_CITY), consumo de gasolina en carretera (FUELCONSUMPTION_HWY) y FUELCONSUMPTION_COMB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9cteGq38Nrds"
   },
   "source": [
    "# Visualize the data in 2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "sbNFj8RMei7j",
    "outputId": "13736ac9-57f5-4ed4-b243-fd8e4581fe7b"
   },
   "outputs": [],
   "source": [
    "Enginesize=data_extract[\"ENGINESIZE\"].values\n",
    "Cylinders=data_extract[\"CYLINDERS\"].values\n",
    "Co2emissions=data_extract[\"CO2EMISSIONS\"].values\n",
    "\n",
    "fig,axs=plt.subplots(1,2)\n",
    "fig=figsize(15,8)\n",
    "\n",
    "axs[0].plot(Enginesize,Co2emissions,\"bo\")\n",
    "axs[0].set_xlabel(\"Engine Size\")\n",
    "axs[0].set_ylabel(\"Co2 Emissions\")\n",
    "axs[0].set_title(\"CO2 EMISSIONS vs ENGINE SIZE \")\n",
    "axs[1].plot(Cylinders,Co2emissions,\"bo\")\n",
    "axs[1].set_xlabel(\"Cylinders\")\n",
    "axs[1].set_ylabel(\"Co2 Emissions\")\n",
    "axs[1].set_title(\"CO2 EMISSIONS vs CYLINDERS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivsQopZb7qCR"
   },
   "source": [
    "Podemos notar que en ambas gráficas la dispersión de los puntos parecen tener un comportamiento lineal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LHqIKzxmT0uL"
   },
   "source": [
    "# Plot 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 466
    },
    "id": "La2UMnG2PqFk",
    "outputId": "51d7e775-dcfc-4873-fc3c-e67a8677c1fb"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "ax = plt.axes(projection ='3d')\n",
    " \n",
    "x = Enginesize\n",
    "y = Cylinders\n",
    "z = Co2emissions\n",
    "ax.plot(x, y, z,\"bo\") \n",
    "\n",
    "ax.set_xlabel('ENGINE SIZE')\n",
    "ax.set_ylabel('CYLINDERS')\n",
    "ax.set_zlabel('CO2 EMISSIONS') \n",
    "ax.set_title('ENGINE SIZE and CYLINDERS vs CO2 EMISSIONS')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfjXEsFQ_dPK"
   },
   "source": [
    "Es posible apreciar que existe un plano al cual se pueden ajustar los puntos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agd8UExbsaZK"
   },
   "source": [
    "# Apply feature scaling.\n",
    "\n",
    "##  It is a step of Data Pre Processing that is applied to independent variables or features of data. It basically helps to normalize the data within a particular range. Sometimes, it also helps in **speeding up the calculations in an algorithm.**\n",
    "\n",
    "We use Standarscaler, it replace the values with their Z score. \n",
    "**Z score** is the number of standard desviations that the values is far away from the mean.\n",
    "\n",
    "$$Z=\\dfrac{x-\\mu}{\\sigma}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bdnYT-4SWmuy",
    "outputId": "7cac902d-bcdb-4c54-9d81-be3d217fc802"
   },
   "outputs": [],
   "source": [
    "# Initialise the Scaler\n",
    "scaler = StandardScaler()\n",
    " \n",
    "# To scale data\n",
    "df=scaler.fit_transform(data_extract)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MC4xqfw-yAUx"
   },
   "source": [
    "Now each column of data is scaled to mean $\\mu=0$ and standard desviation $\\sigma=1$. This values are equivalents to the initials values. The distribution of data stay equal, it is invariant under scale transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "id": "dennBSbjwetp",
    "outputId": "f837a46a-5127-445b-da48-1d8694aab4c1"
   },
   "outputs": [],
   "source": [
    "#Data without Scaler\n",
    "#data_scaler=data_extract\n",
    "\n",
    "#Data with Scaler\n",
    "data_scaler=pd.DataFrame(df,columns=['CO2EMISSIONS','ENGINESIZE','CYLINDERS','FUELCONSUMPTION_CITY','FUELCONSUMPTION_HWY','FUELCONSUMPTION_COMB'])\n",
    "data_scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "09mHzPaD3J4g"
   },
   "source": [
    "# Split the data into train and test using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "peVxRN8w3XPo"
   },
   "outputs": [],
   "source": [
    "# División de los datos en train y test\n",
    "# ==============================================================================\n",
    "#Features \n",
    "X = data_scaler[['ENGINESIZE','CYLINDERS','FUELCONSUMPTION_CITY','FUELCONSUMPTION_HWY','FUELCONSUMPTION_COMB']]\n",
    "#Target variable\n",
    "y = data_scaler[['CO2EMISSIONS']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                  random_state=43,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "45CPm1HfB0pM"
   },
   "source": [
    "División de los datos en Train y Test con una distribución del 80% y 20% del total de datos respectivamente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQikdMSpn7Go"
   },
   "source": [
    "# Train the Linear Model, Predictions from model and Print the Metrics $R^2$, MAE and MAPE. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dDp2FTxln_Vw",
    "outputId": "efb1e4c2-3c08-4164-c80e-7396d5684fa1"
   },
   "outputs": [],
   "source": [
    "#Modelo\n",
    "#==============================================================================\n",
    "linear_regression = LinearRegression()\n",
    "\n",
    "#Entrenamiento del modelo\n",
    "# ==============================================================================\n",
    "linear_regression.fit(X_train,y_train)\n",
    "\n",
    "# Predicciones test\n",
    "# ==============================================================================\n",
    "predicciones = linear_regression.predict(X=X_test)\n",
    "predicciones = predicciones.flatten()\n",
    "\n",
    "#Metric R2\n",
    "# ==============================================================================\n",
    "R2_Train=linear_regression.score(X_train,y_train)\n",
    "R2_Test=linear_regression.score(X_test,y_test)\n",
    "\n",
    "print(\"The R2 for Train set is: {:.4}\".format(R2_Train))\n",
    "print(\"The R2 for Test set is: {:.4} \\n\".format(R2_Test))\n",
    "\n",
    "#Metric MAE\n",
    "# ==============================================================================\n",
    "MAE=mean_absolute_error(y_test,predicciones)\n",
    "\n",
    "print(\"Metric MAE is: {:.4} \\n\".format(MAE))\n",
    "\n",
    "#Metric MAPE\n",
    "# ==============================================================================\n",
    "MAPE=mean_absolute_percentage_error(y_test,predicciones)\n",
    "\n",
    "print(\"Metric MAPE is: {:.4} \\n\".format(MAPE))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fthoMJFACD-i"
   },
   "source": [
    "El modelo tiene un Score $R^2=0.87$ para Test lo cual resulta bastante bien. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvAAXut3v_z_",
    "outputId": "642df33f-fa16-4e28-b6b6-f5e3209f8fbd"
   },
   "outputs": [],
   "source": [
    "#Parameters from Linear Model\n",
    "# ==============================================================================\n",
    "Coef=linear_regression.coef_.flatten()\n",
    "Interc=linear_regression.intercept_.flatten()\n",
    "\n",
    "print(\"Vector of Coeficients from Linear Regression Model: \\n {} \\n\".format(Coef))\n",
    "print(\"Intercept from Linear Regression Model: \\n {}\".format(Interc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-apt5GZQuT5e"
   },
   "source": [
    "# Predict CO2 emission of the 10 randomly chosen cars, compare with the true values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RMshCzbtvNOX",
    "outputId": "0f78a8d5-e176-41d9-b3c7-f7cef428ac14"
   },
   "outputs": [],
   "source": [
    "\n",
    "y_test_array=y_test.values.flatten()\n",
    "\n",
    "#choose 10 randomly cars\n",
    "random=np.random.randint(len(y_test_array), size=10)\n",
    "random_True=[]\n",
    "random_pred=[]\n",
    "for i in random:\n",
    "  random_True.append(y_test_array[i])\n",
    "  random_pred.append(predicciones[i])\n",
    "\n",
    "dict={\"CO2 emission True\":random_True, \"CO2 emission Predict\":random_pred}\n",
    "\n",
    "print(tabulate(dict, headers='keys', tablefmt='fancy_grid')) \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UX7yAyl-D12T"
   },
   "source": [
    "Notamos que hay valores bastante cercanos entre el predicho y el real, mientras que hay otros bastante lejanos entre el predicho y el real. \n",
    "\n",
    "Interpretando el MAE, tenemos que en promedio los datos predichos tienen un error de masomenos 0.2691, es decir, los valores predichos deben interpretarse así: $CO2emission_{pred}\\pm MAE = valor$ $predicho \\pm 0.2691$. \n",
    "\n",
    "Y como en este caso los valores estaban escalados como el número de desviaciones típicas que un valor dado toma con respecto a la media, entonces tenemos un error en el valor predicho bastante significativo.\n",
    "\n",
    "Esto nos lo confirma el MAPE, pues nos está indicando un error porcentual en la predicción de cada emsion de CO2 del $74.2$%, un error significativamente grande.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ufwr2lUFxleP",
    "outputId": "02ba2301-51aa-489b-be59-d1f92600aa9a"
   },
   "outputs": [],
   "source": [
    "#Data without Scaler\n",
    "data_scaler=data_extract\n",
    "\n",
    "# División de los datos en train y test\n",
    "# ==============================================================================\n",
    "#Features \n",
    "X = data_scaler[['ENGINESIZE','CYLINDERS','FUELCONSUMPTION_CITY','FUELCONSUMPTION_HWY','FUELCONSUMPTION_COMB']]\n",
    "#Target variable\n",
    "y = data_scaler[['CO2EMISSIONS']]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,\n",
    "                                                  random_state=43,shuffle=True)\n",
    "\n",
    "#Modelo\n",
    "#==============================================================================\n",
    "linear_regression = LinearRegression()\n",
    "\n",
    "#Entrenamiento del modelo\n",
    "# ==============================================================================\n",
    "linear_regression.fit(X_train,y_train)\n",
    "\n",
    "# Predicciones test\n",
    "# ==============================================================================\n",
    "predicciones = linear_regression.predict(X=X_test)\n",
    "predicciones = predicciones.flatten()\n",
    "\n",
    "#Metric R2\n",
    "# ==============================================================================\n",
    "R2_Train=linear_regression.score(X_train,y_train)\n",
    "R2_Test=linear_regression.score(X_test,y_test)\n",
    "\n",
    "print(\"The R2 for Train set is: {:.4}\".format(R2_Train))\n",
    "print(\"The R2 for Test set is: {:.4} \\n\".format(R2_Test))\n",
    "\n",
    "#Metric MAE\n",
    "# ==============================================================================\n",
    "MAE=mean_absolute_error(y_test,predicciones)\n",
    "\n",
    "print(\"Metric MAE is: {:.4} \\n\".format(MAE))\n",
    "\n",
    "#Metric MAPE\n",
    "# ==============================================================================\n",
    "MAPE=mean_absolute_percentage_error(y_test,predicciones)\n",
    "\n",
    "print(\"Metric MAPE is: {:.4} \\n\".format(MAPE))\n",
    "\n",
    "#Parameters from Linear Model\n",
    "# ==============================================================================\n",
    "Coef=linear_regression.coef_.flatten()\n",
    "Interc=linear_regression.intercept_.flatten()\n",
    "\n",
    "print(\"Vector of Coeficients from Linear Regression Model: \\n {} \\n\".format(Coef))\n",
    "print(\"Intercept from Linear Regression Model: \\n {}\".format(Interc))\n",
    "\n",
    "y_test_array=y_test.values.flatten()\n",
    "\n",
    "#choose 10 randomly cars\n",
    "random=np.random.randint(len(y_test_array), size=10)\n",
    "random_True=[]\n",
    "random_pred=[]\n",
    "for i in random:\n",
    "  random_True.append(y_test_array[i])\n",
    "  random_pred.append(predicciones[i])\n",
    "\n",
    "dict={\"CO2 emission True\":random_True, \"CO2 emission Predict\":random_pred}\n",
    "\n",
    "print(tabulate(dict, headers='keys', tablefmt='fancy_grid')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UsbrMlGBHmHs"
   },
   "source": [
    "Para los datos sin Escalar, obtenemos resultados más acordes con las métricas obtenidas. Pues en la predicción de cada valor tenemos un error así: \n",
    "\n",
    "$$valor_{predicho} \\pm 17.05$$\n",
    "\n",
    "Cabe recalcar qeu MAE está en la misma escala que la variable objetivo.\n",
    "\n",
    "E interpretando MAPE, en cada valor predicho tenemos un $6.274$% de error respecto a los valores reales.\n",
    "\n",
    "Todo esto resulta genial, nuestro modelo sirve para predecir CO2 emissions. Y ahora sí, podemos decir que todo el modelo tiene un rendimiento muy bueno, el cual es reportado por $R^2$ $Score=87$%.\n",
    "\n",
    "###**En Conclusión**\n",
    "\n",
    "Para estos datos es más conveniente no usar un escalador de los datos, pues aunque estamos en una regresión lineal y usar esto supone un mejor rendimiento del algorimo, en este caso nos lleva a pérdidas de interpretabilidad. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pSnIUtqDHDrc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8pXRgPUoHKT7"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Neural_Network_Course_Homework_4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
