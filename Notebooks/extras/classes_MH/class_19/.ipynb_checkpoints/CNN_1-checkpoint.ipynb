{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "employed-september",
   "metadata": {},
   "source": [
    "## Convolutional Neural Networks - introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "superior-danish",
   "metadata": {},
   "source": [
    "Long time before CNN Image processing allows better extracion of the images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decent-marathon",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"imgs/edges_detection.jpg\" width=\"800\" /> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metropolitan-bhutan",
   "metadata": {},
   "source": [
    "- NN were already powerful (NN,CNN start dominating over other ML lagorithms)\n",
    "- The advancements in Computer Vision with Deep Learning has been constructed and perfected with time, primarily over one particular algorithm — a Convolutional Neural Network. (CNN -  breakthrough in image classification was made by CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fixed-testament",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"imgs/CNN.jpeg\" width=\"600\" /> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-gates",
   "metadata": {},
   "source": [
    "### What is image\n",
    "* An image is a collection of pixels. For example, a 32-by-32 image has 32×32=1024 pixels.\n",
    "* Each pixel is an intensity represented by a number in the range [0,255], 0 is black and 255 is white.\n",
    "* Color images have three dimensions: [width, height, depth] where depth is usually 3. Why is depth 3? That’s because it encodes the intensity of [Red, Green, Blue], i.e., RGB values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rapid-functionality",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"imgs/image_pixel.png\" width=\"600\" /> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranging-madison",
   "metadata": {},
   "source": [
    "# If the input is a digit (2D, 3D array of number)\n",
    "In case of Color image we have 3D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-customer",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"imgs/RGB.png\" width=\"600\" /> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-bedroom",
   "metadata": {},
   "source": [
    "## Convolution process\n",
    "* Image (6x6)\n",
    "* Filter / Kernel (3x3)\n",
    "* Pooling (2x2)\n",
    "* Output (2x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-legislation",
   "metadata": {},
   "source": [
    "A kernel is a small 2D matrix whose contents are based upon the operations to be performed. A kernel maps on the input image by simple matrix multiplication and addition, the output obtained is of lower dimensions and therefore easier to work with."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "important-racing",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"imgs/convolution_process.png\" width=\"1000\" /> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "objective-maker",
   "metadata": {},
   "source": [
    "# Just the convolution part (gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affiliated-verse",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"imgs/kernel.gif\" width=\"400\" /> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-notification",
   "metadata": {},
   "source": [
    "# But the image has three layers so the kernel works on each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affecting-highland",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"imgs/kernel3D.gif\" width=\"800\" /> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "forbidden-stanford",
   "metadata": {},
   "source": [
    "# Different kernels make different operations on the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dietary-dakota",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"imgs/convolution_kernel_example2.png\" width=\"800\" /> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "demanding-popularity",
   "metadata": {},
   "source": [
    "## in CNN the filter weights learn through backpropagation!!!! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functioning-cherry",
   "metadata": {},
   "source": [
    "## In tensorflow the Convolution layer is being implemented with the following syntax\n",
    "`from tensorflow.keras.layers import Conv2D`  \n",
    "`Conv2D(filters=16,  strides=1, padding='SAME', kernel_size=(3, 3), activation='relu', name='conv_1')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incident-jerusalem",
   "metadata": {},
   "source": [
    "# Max pooling is another operation on the image after the convolution it finds the maximum value in the given `pool size`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jewish-public",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"imgs/pooling.jpg\" width=\"600\" /> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "narrative-tribune",
   "metadata": {},
   "source": [
    "## In tensorflow the Pooling layer is being implemented with the following syntax:\n",
    "`from tensorflow.keras.layers import MaxPooling2D`\n",
    "`MaxPooling2D(pool_size=(2, 2), name='pool_1')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conditional-timothy",
   "metadata": {},
   "source": [
    "# After the convolution and max pooling is done we flatten the image (or whats left from it)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-leeds",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"imgs/flattening.png\" width=\"600\" /> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-jumping",
   "metadata": {},
   "source": [
    "* Depth: The number of filters to use for each layer.  \n",
    "* Stride: How big of a step to take when sliding the filter across the image, usually 1 (see the convolution GIF above) or 2.\n",
    "* Size: Size of each convolution filter, e.g., the mean filter is 3-by-3.\n",
    "* Padding: Whether to use paddings around images when doing convolution. This determines the output image size. (default padding='valid')\n",
    "  * `valid` means no padding (as above) so the output image is smaller as input\n",
    "  * `SAME` means the output image is the same as input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-microphone",
   "metadata": {},
   "source": [
    "## In tensorflow the Flattening layer is being implemented with the following syntax:\n",
    "`from tensorflow.keras.layers import Flatten`\n",
    "`Flatten(name='flatten_layer')`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foreign-cornwall",
   "metadata": {},
   "source": [
    "## The order of the layers in CNN:\n",
    "* Input layer    \n",
    "* Convolution layer\n",
    "* Pooling layer\n",
    "* Convolution layer\n",
    "* Pooling layer\n",
    "* Convolution layer\n",
    "* Pooling layer\n",
    "* Flattening layer\n",
    "* Dense layer\n",
    "* Dense layer\n",
    "* output layer ( in case of classification the activation function is: `Sigmoid`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-masters",
   "metadata": {},
   "source": [
    "# CNN with Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "norman-emerald",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
