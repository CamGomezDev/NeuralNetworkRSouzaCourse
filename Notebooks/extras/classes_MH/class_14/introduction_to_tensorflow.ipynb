{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "figured-paradise",
   "metadata": {},
   "source": [
    "# TensorFlow - semiformal introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "developed-finance",
   "metadata": {},
   "source": [
    "* developed by Google Brain team\n",
    "* backend in C/C++ so its faster than pure Python\n",
    "* main task: Machine learning and Deep Neural Networks (created for that)\n",
    "* lot of build-in mathematical functions for NN\n",
    "* well optimized\n",
    "* can perform parallel computing\n",
    "* supports CPU, GPU "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "offshore-weight",
   "metadata": {},
   "source": [
    "## TF structure is based on dataflow graph\n",
    "* this part is just to make you aware of the depth of TensorFlow as framework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "black-liechtenstein",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"imgs/tf_graph.png\" width=\"800\" /> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-bloom",
   "metadata": {},
   "source": [
    "    * nodes: mathematical operations\n",
    "    * edges: multidimensional arrays (tensors TensorFlow)   \n",
    "    * standard usage is build >> execute\n",
    "    * tensors: examples\n",
    "    * example of 3D tensor color image (RGB)\n",
    "    * in data flow graph the NODES are called operations - units of computation\n",
    "    * the edges are tensors (data produces by mathematical operation)\n",
    "    * tf.placeholder() - hole through the graph can be feeded with data (feature matrix)\n",
    "    * we initialize the placeholders before using them\n",
    "    * tf.Variable() is a matrix of variables (coefficients: $\\theta$s)\n",
    "    * weight matrix and feature matrix is matrix multiplication:\n",
    "\n",
    "$$ \\theta =\n",
    "\\begin{bmatrix}\n",
    "\\theta_{0} \\\\\n",
    "\\theta_{1} \\\\\n",
    "\\theta_{2} \\\\\n",
    "\\vdots\\\\\n",
    "\\theta_{n}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "$$ X=\n",
    "\\begin{bmatrix}\n",
    "1 \\\\\n",
    "x_{1} \\\\\n",
    "x_{2} \\\\\n",
    "\\vdots\\\\\n",
    "x_{n}\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "      $$\\theta^TX = \\theta_0 + \\theta_1 x_1 + \\theta_2 x_2$$\n",
    "* the output of each operation is a tensor      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-representation",
   "metadata": {},
   "source": [
    "### Tensorflow architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "renewable-subscription",
   "metadata": {},
   "source": [
    "<table><tr>\n",
    "<td> <img src=\"imgs/tf_architecture.png\" width=\"700\" /> </td>\n",
    "</tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compact-daisy",
   "metadata": {},
   "source": [
    "* front end - the interaction part - building the code in Python is simple and quick\n",
    "* the powerr of Tf is that you can build it once and run on anything even mobile phone"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-montgomery",
   "metadata": {},
   "source": [
    "### TensorFlow 2.x and \"Eager Execution\" \n",
    "* TF 2.0 big improvement:\n",
    "   * Keras is a part of TF - high-level API\n",
    "   * Keras is for NN - very user friendly\n",
    "   * Keras does not have his own execution engine! so it depened on other framework like     Theano or Pytorch, or TensorFlow\n",
    "   * performance optimization and support for CPU and GPU acceleration\n",
    "   * new feature: eager execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "infinite-daughter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(32.0, shape=(), dtype=float64)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The Session graph is empty.  Add operations to the graph before calling run().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-6a489f43ad14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# when one creates \"session\" then the value is assigned to 'c'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    966\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 968\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    969\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1114\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Attempted to use a closed Session.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1115\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1116\u001b[0;31m       raise RuntimeError('The Session graph is empty.  Add operations to the '\n\u001b[0m\u001b[1;32m   1117\u001b[0m                          'graph before calling run().')\n\u001b[1;32m   1118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The Session graph is empty.  Add operations to the graph before calling run()."
     ]
    }
   ],
   "source": [
    "# this was old tensorflow v1\n",
    "\n",
    "# You will not really need this - its just to explain some elements\n",
    "# we initialize two tensors a,b  \n",
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "a=tf.constant(np.array([1.0,2.0,3.0]))\n",
    "b=tf.constant(np.array([4.0,5.0,6.0]))\n",
    "c=tf.tensordot(a,b,1)\n",
    "print(type(c))\n",
    "print(c)\n",
    "# until here nothing happens\n",
    "\n",
    "# when one creates \"session\" then the value is assigned to 'c'\n",
    "session = tf.Session()\n",
    "output = session.run(c)\n",
    "session.close()\n",
    "\n",
    "# that made TF code hard to debug"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adequate-disorder",
   "metadata": {},
   "source": [
    "* until here TF was not so popular\n",
    "* eager execution mean the code is executed \"line-by-line\" and intermediate results are accesible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "crazy-plate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32.0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.compat.v1 as tf\n",
    "import numpy as np\n",
    "a=tf.constant(np.array([1.0,2.0,3.0]))\n",
    "b=tf.constant(np.array([4.0,5.0,6.0]))\n",
    "c=tf.tensordot(a,b,1)\n",
    "c.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scheduled-mistress",
   "metadata": {},
   "source": [
    "# Basically tensorflow has his own datatype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "complicated-conservation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[[[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]], shape=(2, 3, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "var1=tf.ones([1,2,3])\n",
    "var2=tf.zeros([2,3,2])\n",
    "print(type(var1))\n",
    "print(var2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "patient-there",
   "metadata": {},
   "outputs": [],
   "source": [
    "# But we can still use Numpy (and we will)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adopted-pioneer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]\n",
      "\n",
      " [[0. 0.]\n",
      "  [0. 0.]\n",
      "  [0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "var3=np.zeros([2,3,2])\n",
    "var4=np.ones([1,2,3])\n",
    "print(type(var3))\n",
    "print(var3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-penguin",
   "metadata": {},
   "source": [
    "# First example with TensorFlow\n",
    "\n",
    "#### mnist digits classification using TensorFlow Neural Network - very quick guide - all will be explained better later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "reserved-eagle",
   "metadata": {},
   "source": [
    "# Principle elements of building Neural Network using TensorFlow:\n",
    "\n",
    "* prepare the data\n",
    "  * data X_train,y_train X_test,y_test (using scikit-learn )\n",
    "* create a sequential model\n",
    "  * model.compile\n",
    "  * model.fit\n",
    "  * model.evaluate\n",
    "  * model.predict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "former-knitting",
   "metadata": {},
   "source": [
    "### Sequential model accepts different layers\n",
    "InputLayer, Dense, Flatten, Conv2D, MaxPool2D, Dropout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latin-practice",
   "metadata": {},
   "source": [
    "* InputLayer specifies the input shape of the data (mnist)\n",
    "   * how to get the proper dimensions: X_train[0].shape\n",
    "* Dense is a standard neural network layer\n",
    "   * dense accepts number of neurons and the activation function and label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "chief-measure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "heated-drinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "progressive-reduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Softmax, InputLayer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "running-belarus",
   "metadata": {},
   "source": [
    "Must read the documentation!\n",
    "type: tensorflow InputLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "similar-court",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential([InputLayer(input_shape=(784,)),\n",
    "                  Dense(units=16,activation='relu',name='hidden_relu'),\n",
    "                  Dense(units=10,activation='softmax',name='output_softmax')\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lonely-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "later-radiation",
   "metadata": {},
   "source": [
    "### Compile the model with given parameters\n",
    "* optimizer (adam,sgd)\n",
    "* loss function, for mnist try: 'sparse_categorical_crossentropy'\n",
    "* metrics (most common is accuracy) (how to measure the performance of the NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-indication",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-throat",
   "metadata": {},
   "source": [
    "### Fitting (training) the model with given parameters\n",
    "* accepts X_train,y_train (and evaluation data ... later)\n",
    "* epochs - number of passes (remember gradient descent)\n",
    "* batch_size like a size of a package (default is 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "mhistory=model.fit(X_train, y_train, epochs=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dominant-heart",
   "metadata": {},
   "source": [
    "myhistory is to visualize the progres (is a dictionary )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "overall-packing",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(myhistory.history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "encouraging-earth",
   "metadata": {},
   "source": [
    "### Predict (check the model state of training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "every-wells",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-38f7eb8aa182>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# accepts slices of data. Use X_test for prediction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m11\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# accepts slices of data. Use X_test for prediction\n",
    "pred = model.predict(X_test[0:1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unlimited-indicator",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
